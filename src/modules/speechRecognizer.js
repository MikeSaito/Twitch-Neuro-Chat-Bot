import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';
import { fileURLToPath } from 'url';
import { LocalWhisper } from './localWhisper.js';
import { ProxyAPI } from './proxyAPI.js';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

export class SpeechRecognizer {
  constructor(config) {
    this.config = config;
    this.useLocal = config.useLocal || false;
    this.useProxyAPI = config.useProxyAPI || false;
    
    if (this.useLocal) {
      this.localWhisper = new LocalWhisper({
        modelPath: config.localWhisperModel || 'base',
        device: config.localWhisperDevice || 'cpu',
        language: 'ru',
      });
    } else if (this.useProxyAPI) {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º ProxyAPI
      this.proxyAPI = new ProxyAPI({
        apiKey: config.proxyAPIKey,
        baseUrl: config.proxyAPIBaseUrl,
        provider: config.proxyAPIProvider,
        model: config.proxyAPIWhisperModel,
      });
      this.openai = this.proxyAPI.getOpenAIClient();
      console.log('[SpeechRecognizer] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è ProxyAPI –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏');
    } else {
      // –ü—Ä—è–º–æ–π OpenAI API
      this.openai = new OpenAI({
        apiKey: config.apiKey,
      });
    }
    
    this.audioCache = new Map();
  }

  async init() {
    if (this.useLocal && this.localWhisper) {
      await this.localWhisper.init();
    }
  }

  /**
   * –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–∑ –±—É—Ñ–µ—Ä–∞ (–ø–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º)
   * –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ—Ç —Ä–µ—á—å
   */
  async recognizeFromStream(audioBuffer) {
    if (!audioBuffer || audioBuffer.length === 0) {
      console.log('[SpeechRecognizer] ‚ö†Ô∏è –ü—É—Å—Ç–æ–π –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä');
      return {
        text: null,
        confidence: 0,
        timestamp: Date.now(),
      };
    }

    console.log(`[SpeechRecognizer] üé§ –ü–æ–ª—É—á–µ–Ω –∞—É–¥–∏–æ –±—É—Ñ–µ—Ä: ${audioBuffer.length} –±–∞–π—Ç (–ø–æ—Ç–æ–∫–æ–≤—ã–π —Ä–µ–∂–∏–º)`);

    try {
      // –ò—Å–ø–æ–ª—å–∑—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper –µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω
      if (this.useLocal && this.localWhisper) {
        console.log('[SpeechRecognizer] üé§ –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–æ–∫–∞–ª—å–Ω—ã–π Whisper (–ø–æ—Ç–æ–∫)');
        const result = await this.localWhisper.recognizeFromStream(audioBuffer);
        if (result.text) {
          console.log(`[SpeechRecognizer] ‚úÖ –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢: "${result.text}"`);
          console.log(`[SpeechRecognizer] üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: ${(result.confidence * 100).toFixed(1)}%`);
        } else {
          console.log('[SpeechRecognizer] ‚ö†Ô∏è –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ (–ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)');
        }
        return result;
      }

      // –ò–Ω–∞—á–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º OpenAI API
      const tempPath = path.join(__dirname, '../../temp_audio.mp3');
      await fs.writeFile(tempPath, audioBuffer);

      const whisperModel = this.useProxyAPI 
        ? (this.config.proxyAPIWhisperModel || 'gpt-4o-transcribe')
        : 'whisper-1';
      
      console.log(`[SpeechRecognizer] üé§ –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ ${this.useProxyAPI ? 'ProxyAPI' : 'OpenAI'} (–º–æ–¥–µ–ª—å: ${whisperModel})`);
      const transcription = await this.openai.audio.transcriptions.create({
        file: await fs.readFile(tempPath),
        model: whisperModel,
        language: 'ru',
        response_format: 'verbose_json',
      });

      await fs.unlink(tempPath).catch(() => {});

      const result = {
        text: transcription.text,
        confidence: transcription.segments?.[0]?.no_speech_prob 
          ? 1 - transcription.segments[0].no_speech_prob 
          : 0.8,
        language: transcription.language,
        segments: transcription.segments,
        timestamp: Date.now(),
      };

      if (result.text) {
        console.log(`[SpeechRecognizer] ‚úÖ –†–ê–°–ü–û–ó–ù–ê–ù–ù–´–ô –¢–ï–ö–°–¢: "${result.text}"`);
        console.log(`[SpeechRecognizer] üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: ${(result.confidence * 100).toFixed(1)}%, –Ø–∑—ã–∫: ${result.language}`);
      } else {
        console.log('[SpeechRecognizer] ‚ö†Ô∏è –†–µ—á—å –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–∞ (–ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç)');
      }

      return result;
    } catch (error) {
      console.error('[SpeechRecognizer] –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è:', error);
      return {
        text: null,
        confidence: 0,
        error: error.message,
        timestamp: Date.now(),
      };
    }
  }

  async recognizeFromFile(filePath) {
    try {
      const audioBuffer = await fs.readFile(filePath);
      return await this.recognizeFromStream(audioBuffer);
    } catch (error) {
      console.error('[SpeechRecognizer] –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞:', error);
      return {
        text: null,
        confidence: 0,
        error: error.message,
        timestamp: Date.now(),
      };
    }
  }

  // –ú–µ—Ç–æ–¥ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞ (—Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏)
  async captureAudioFromBrowser(page) {
    // –≠—Ç–æ —Å–ª–æ–∂–Ω–∞—è –∑–∞–¥–∞—á–∞, —Ç—Ä–µ–±—É—é—â–∞—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Web Audio API
    // –∏–ª–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π –±—Ä–∞—É–∑–µ—Ä–∞
    // –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:
    // 1. Puppeteer/Playwright —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è–º–∏ –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∞—É–¥–∏–æ
    // 2. –í–Ω–µ—à–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã —Ç–∏–ø–∞ FFmpeg –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –∞—É–¥–∏–æ
    // 3. API Twitch –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∞—É–¥–∏–æ –ø–æ—Ç–æ–∫–∞ –Ω–∞–ø—Ä—è–º—É—é
    
    console.warn('[SpeechRecognizer] –ó–∞—Ö–≤–∞—Ç –∞—É–¥–∏–æ –∏–∑ –±—Ä–∞—É–∑–µ—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏');
    return null;
  }
}
